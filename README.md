# Multimodale Mensch-Maschine-Interaktion 

## Bearbeiter/in

Stötzner, Moritz, 55492

## Hand-eye Coordination for Textual Difficulty Detection in Text Summarization

Das Paper untersucht, ob und wie das kognitive Verhalten bei dem Zusammenfassen eines Textes Rückschlüsse über die Schwierigkeit jenes Textes (bzw. das Verständnis des Lesers) geben kann. Dafür ließen die Autoren Probanden drei verschieden schwere Texte zusammenfassen, während sie Augenbewegung und Schreibverhalten untersuchten. Dafür extrahierten sie Features aus den Modalitäten des Eye Trackers und des Keyboards sowie aus zeitlichen Messungen. So unterschieden sie mittels des Eye Trackings, ob wir den Text mit unserem Blick gründlich lesen oder nur überfliegen. Gemessen wurden auch Metriken des Tippverhaltens wie etwa die durchschnittliche Anzahl Wörter pro Sekunde. Von diesen Features wurden einige relevante selektiert und ein Machine-Learning Modell konstruiert, welches den Schwierigkeitsgrades eines Text sicher vorhersagt. Um zu zeigen, dass ihre multimediale Methode eine insgesamt genauere Vorhersage leistet als unimodale Modelle, erstellten die Forscher noch Modelle, welche nur mit Features einer isolierten Modalität trainiert wurden. Diese Modelle konnten nicht mit der multimodalen Version mithalten. Die Forscher möchten ihr Experiment mit einer größeren Probe von Texten wiederholen und Modalitäten der Computermaus mit einbeziehen. 

## 

